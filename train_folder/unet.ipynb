{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore # type: ignore\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n",
      "2.0.2\n",
      "2.18.0\n",
      "2.6.0+cpu\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "print(torch.__version__)\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "\n",
    "##### Normalizing the dataset\n",
    "##### Onehotencoding on segmentation Mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: Dataset/volume_pt1\\volume-0.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-0.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-1.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-1.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-10.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-10.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-2.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-2.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-3.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-3.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-4.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-4.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-5.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-5.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-6.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-6.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-7.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-7.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-8.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-8.nii\n",
      "Loading file: Dataset/volume_pt1\\volume-9.nii\n",
      "Loading file: Dataset/volume_pt1/segementation\\segmentation-9.nii\n",
      "Training data shape: (5277, 128, 128)\n",
      "Segmentation mask shape: (5277, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "VOLUME_DIR = \"Dataset/volume_pt1\" \n",
    "SEGMENTATION_DIR = \"Dataset/volume_pt1/segementation\"\n",
    "IMG_SIZE = (128, 128) \n",
    "\n",
    "def load_nifti(file_path):\n",
    "    \"\"\"Load a NIfTI file and return the NumPy array\"\"\"\n",
    "    print(f\"Loading file: {file_path}\") \n",
    "    nifti_img = nib.load(file_path) \n",
    "    return nifti_img.get_fdata()\n",
    "\n",
    "def preprocess_data(volume_path, segmentation_path):\n",
    "    \"\"\"Load and preprocess volume and segmentation data\"\"\"\n",
    "    volume_data = load_nifti(volume_path)\n",
    "    segmentation_data = load_nifti(segmentation_path).astype(int)\n",
    "\n",
    "    volume_data = (volume_data - np.min(volume_data)) / (np.max(volume_data) - np.min(volume_data))\n",
    "\n",
    "    volume_resized = np.array([resize(slice, IMG_SIZE, mode='constant', preserve_range=True) for slice in volume_data.transpose(2, 0, 1)])\n",
    "    segmentation_resized = np.array([resize(slice, IMG_SIZE, mode='constant', preserve_range=True, order=0) for slice in segmentation_data.transpose(2, 0, 1)])\n",
    "\n",
    "   \n",
    "    segmentation_onehot = to_categorical(segmentation_resized, num_classes=3)\n",
    "\n",
    "    return volume_resized, segmentation_onehot\n",
    "\n",
    "\n",
    "X_train, Y_train = [], []\n",
    "\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(VOLUME_DIR) if f.endswith(\".nii\")])\n",
    "mask_files = sorted([f for f in os.listdir(SEGMENTATION_DIR) if f.endswith(\".nii\")])\n",
    "\n",
    "for img_file, mask_file in zip(image_files, mask_files):\n",
    "    volume_path = os.path.join(VOLUME_DIR, img_file)\n",
    "    segmentation_path = os.path.join(SEGMENTATION_DIR, mask_file)\n",
    "    vol, seg = preprocess_data(volume_path, segmentation_path)\n",
    "    X_train.append(vol)\n",
    "    Y_train.append(seg)\n",
    "# Shape: (num_slices, 128, 128)\n",
    "# Shape: (num_slices, 128, 128, 3)\n",
    "X_train = np.concatenate(X_train, axis=0)  \n",
    "Y_train = np.concatenate(Y_train, axis=0)  \n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Segmentation mask shape:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Design \n",
    "\n",
    "#### Activation Function-Relu\n",
    "#### Maxpolling\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Model # type: ignore\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Concatenate # type: ignore\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "from tensorflow.keras.losses import categorical_crossentropy # type: ignore\n",
    "import tensorflow.keras.backend as K # type: ignore\n",
    "from skimage.transform import resize\n",
    "import nibabel as nib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---- Dice Coefficient and Loss ----\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "def dice_loss(y_true, y_pred):\n",
    "    return 1 - dice_coefficient(y_true, y_pred)\n",
    "\n",
    "# ---- U-Net Model ----\n",
    "def unet_model(input_size=(128, 128, 1), num_classes=3):\n",
    "    inputs = Input(input_size)\n",
    "\n",
    "    # Encoder\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    c1 = Conv2D(32, (3, 3), activation='relu', padding='same')(c1)\n",
    "    p1 = MaxPooling2D((2, 2))(c1)\n",
    "\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(p1)\n",
    "    c2 = Conv2D(64, (3, 3), activation='relu', padding='same')(c2)\n",
    "    p2 = MaxPooling2D((2, 2))(c2)\n",
    "\n",
    "    # Bottleneck\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(p2)\n",
    "    c3 = Conv2D(128, (3, 3), activation='relu', padding='same')(c3)\n",
    "\n",
    "    # Decoder\n",
    "    u1 = UpSampling2D((2, 2))(c3)\n",
    "    u1 = Concatenate()([u1, c2])\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(u1)\n",
    "    c4 = Conv2D(64, (3, 3), activation='relu', padding='same')(c4)\n",
    "\n",
    "    u2 = UpSampling2D((2, 2))(c4)\n",
    "    u2 = Concatenate()([u2, c1])\n",
    "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(u2)\n",
    "    c5 = Conv2D(32, (3, 3), activation='relu', padding='same')(c5)\n",
    "\n",
    "    # Output Layer (Softmax for Multi-Class)\n",
    "    outputs = Conv2D(num_classes, (1, 1), activation='softmax')(c5)\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training Unet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam # type: ignore # type: ignore\n",
    "# 0.001 (default) → Good for general training\n",
    "LEARNING_RATE = 0.001 \n",
    "\n",
    "# Define and compile model\n",
    "model = unet_model()\n",
    "optimizer = Adam(learning_rate=LEARNING_RATE)  # Set learning rate\n",
    "model.compile(optimizer=optimizer, loss=categorical_crossentropy, metrics=['accuracy', dice_coefficient])\n",
    "\n",
    "# Train model\n",
    "EPOCHS = 20\n",
    "BATCH_SIZE = 16\n",
    "history = model.fit(X_train, Y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"unet_liver_segmentation.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: test_folder\\volume-10.nii\n",
      "Loading: test_folder\\segmentation\\segmentation-10.nii\n",
      "Final Test Data Shape: (501, 128, 128, 1)\n",
      "Final Test Mask Shape: (501, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "# Function to load NIfTI files\n",
    "def load_nifti(file_path):\n",
    "    \"\"\"Load a NIfTI file and return the NumPy array\"\"\"\n",
    "    print(f\"Loading: {file_path}\")  # Debugging: Print file being loaded\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    nifti_img = nib.load(file_path)\n",
    "    return nifti_img.get_fdata()\n",
    "\n",
    "# Function to preprocess test data\n",
    "def preprocess_data(test_volume_path, test_segmentation_path):\n",
    "    \"\"\"Load and preprocess a single test volume and its corresponding segmentation mask\"\"\"\n",
    "    volume_data = load_nifti(test_volume_path)\n",
    "    segmentation_data = load_nifti(test_segmentation_path).astype(int)\n",
    "\n",
    "    # Normalize CT images (0-1)\n",
    "    volume_data = (volume_data - np.min(volume_data)) / (np.max(volume_data) - np.min(volume_data))\n",
    "\n",
    "    # Resize to (128, 128)\n",
    "    from skimage.transform import resize\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    volume_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True)\n",
    "        for slice in volume_data.transpose(2, 0, 1)  # Rearrange to (slices, H, W)\n",
    "    ])\n",
    "    \n",
    "    segmentation_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True, order=0) \n",
    "        for slice in segmentation_data.transpose(2, 0, 1)\n",
    "    ])\n",
    "\n",
    "    # One-hot encode segmentation masks (background=0, liver=1, tumor=2)\n",
    "    \n",
    "    segmentation_onehot = to_categorical(segmentation_resized, num_classes=3)\n",
    "\n",
    "    return volume_resized, segmentation_onehot\n",
    "\n",
    "# ---- Load Test Data ----\n",
    "test_image_path = os.path.join(\"test_folder\") \n",
    "test_mask_path = os.path.join(\"test_folder\", \"segmentation\") \n",
    "\n",
    "# Ensure directories exist\n",
    "if not os.path.exists(test_image_path) or not os.path.exists(test_mask_path):\n",
    "    raise FileNotFoundError(\"Test data folder or segmentation folder not found!\")\n",
    "\n",
    "# Get sorted filenames\n",
    "image_files = sorted([f for f in os.listdir(test_image_path) if f.endswith(\".nii\")])\n",
    "mask_files = sorted([f for f in os.listdir(test_mask_path) if f.endswith(\".nii\")])\n",
    "\n",
    "# Check if the number of images and masks match\n",
    "if len(image_files) != len(mask_files):\n",
    "    raise ValueError(\"Mismatch between the number of test images and segmentation masks!\")\n",
    "\n",
    "X_test, Y_test = [], []\n",
    "\n",
    "# Load and preprocess each test image and mask\n",
    "for img_file, mask_file in zip(image_files, mask_files):\n",
    "    volume_path = os.path.join(test_image_path, img_file)  # Correct path joining\n",
    "    segmentation_path = os.path.join(test_mask_path, mask_file)  # Correct path joining\n",
    "\n",
    "    vol, seg = preprocess_data(volume_path, segmentation_path)\n",
    "    X_test.append(vol)\n",
    "    Y_test.append(seg)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_test = np.array(X_test)  # Shape: (num_volumes, num_slices, 128, 128)\n",
    "Y_test = np.array(Y_test)  # Shape: (num_volumes, num_slices, 128, 128, 3)\n",
    "\n",
    "# Reshape to flatten across all slices\n",
    "X_test = X_test.reshape(-1, 128, 128, 1)  # Add channel dimension\n",
    "Y_test = Y_test.reshape(-1, 128, 128, 3)  # Keep segmentation masks in one-hot format\n",
    "\n",
    "# Print shapes\n",
    "print(\"Final Test Data Shape:\", X_test.shape)  # (total_slices, 128, 128, 1)\n",
    "print(\"Final Test Mask Shape:\", Y_test.shape)  # (total_slices, 128, 128, 3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the Model and then testing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import load_model # type: ignore\n",
    "\n",
    "# ---- Load the trained model ----\n",
    "model = load_model(\"unet_liver_segmentation.h5\", compile=False)  # Load without compiling\n",
    "\n",
    "# ---- Make predictions ----\n",
    "y_pred = model.predict(X_test)  # Shape: (total_slices, 128, 128, 3)\n",
    "\n",
    "# Convert predicted probabilities to class labels (0=background, 1=liver, 2=tumor)\n",
    "y_pred_labels = np.argmax(y_pred, axis=-1)  # Shape: (total_slices, 128, 128)\n",
    "\n",
    "# Convert actual one-hot masks to class labels\n",
    "Y_test_labels = np.argmax(Y_test, axis=-1)  # Shape: (total_slices, 128, 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---- Display some slices ----\n",
    "num_slices = 3  # Number of slices to display\n",
    "fig, axes = plt.subplots(num_slices, 3, figsize=(10, num_slices * 3))\n",
    "\n",
    "for i in range(num_slices):\n",
    "    slice_idx = i   # Adjust step to view different slices\n",
    "\n",
    "    # Display CT Image\n",
    "    axes[i, 0].imshow(X_test[slice_idx, :, :, 0], cmap='gray')\n",
    "    axes[i, 0].set_title(f\"Slice {slice_idx} - CT Image\")\n",
    "\n",
    "    # Display Actual Mask\n",
    "    axes[i, 1].imshow(Y_test_labels[slice_idx], cmap='jet')\n",
    "    axes[i, 1].set_title(\"Actual Mask\")\n",
    "\n",
    "    # Display Predicted Mask\n",
    "    axes[i, 2].imshow(y_pred_labels[slice_idx], cmap='jet')\n",
    "    axes[i, 2].set_title(\"Predicted Mask\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "##Dice Score is Implemented Here\n",
    "import numpy as np\n",
    "import tensorflow.keras.backend as K  # type: ignore\n",
    "import tensorflow as tf\n",
    "\n",
    "def iou_coefficient(y_true, y_pred, smooth=1):\n",
    "    \"\"\"Calculate the Intersection over Union (IoU) for binary mask.\"\"\"\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "    y_pred = K.cast(y_pred, \"float32\")\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
    "    return (intersection + smooth) / (union + smooth)\n",
    "\n",
    "def precision(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "    y_pred = K.cast(y_pred, \"float32\")\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    tp = K.sum(y_true_f * y_pred_f)\n",
    "    fp = K.sum(y_pred_f) - tp\n",
    "    return tp / (tp + fp + K.epsilon())\n",
    "\n",
    "def recall(y_true, y_pred):\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "    y_pred = K.cast(y_pred, \"float32\")\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    tp = K.sum(y_true_f * y_pred_f)\n",
    "    fn = K.sum(y_true_f) - tp\n",
    "    return tp / (tp + fn + K.epsilon())\n",
    "\n",
    "def f1_score(y_true, y_pred):\n",
    "    prec = precision(y_true, y_pred)\n",
    "    rec = recall(y_true, y_pred)\n",
    "    return 2 * (prec * rec) / (prec + rec + K.epsilon())\n",
    "\n",
    "def dice_coefficient(y_true, y_pred, smooth=1):\n",
    "    \"\"\"Calculate Dice coefficient.\"\"\"\n",
    "    y_true = K.cast(y_true, \"float32\")\n",
    "    y_pred = K.cast(y_pred, \"float32\")\n",
    "    y_true_f = K.flatten(y_true)\n",
    "    y_pred_f = K.flatten(y_pred)\n",
    "    intersection = K.sum(y_true_f * y_pred_f)\n",
    "    return (2. * intersection + smooth) / (K.sum(y_true_f) + K.sum(y_pred_f) + smooth)\n",
    "\n",
    "# Convert predictions and ground truths to class labels\n",
    "y_pred_labels = np.argmax(y_pred, axis=-1)  # Shape: (total_slices, 128, 128)\n",
    "Y_test_labels = np.argmax(Y_test, axis=-1)  # Shape: (total_slices, 128, 128)\n",
    "\n",
    "# Compute class-wise metrics\n",
    "num_classes = 3  # Background, Liver, Tumor\n",
    "for class_idx in range(num_classes):\n",
    "    print(f\"\\nMetrics for Class {class_idx}:\")\n",
    "    y_true_class = tf.convert_to_tensor((Y_test_labels == class_idx).astype(np.float32))\n",
    "    y_pred_class = tf.convert_to_tensor((y_pred_labels == class_idx).astype(np.float32))\n",
    "\n",
    "    iou = K.eval(iou_coefficient(y_true_class, y_pred_class))\n",
    "    prec = K.eval(precision(y_true_class, y_pred_class))\n",
    "    rec = K.eval(recall(y_true_class, y_pred_class))\n",
    "    f1 = K.eval(f1_score(y_true_class, y_pred_class))\n",
    "    dice = K.eval(dice_coefficient(y_true_class, y_pred_class))\n",
    "\n",
    "    print(f\"IoU: {iou:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Dice Coefficient: {dice:.4f}\")\n",
    "\n",
    "# Extra: Dice for Liver + Tumor combined\n",
    "liver_tumor_true = tf.convert_to_tensor(((Y_test_labels == 1) | (Y_test_labels == 2)).astype(np.float32))\n",
    "liver_tumor_pred = tf.convert_to_tensor(((y_pred_labels == 1) | (y_pred_labels == 2)).astype(np.float32))\n",
    "dice_liver_tumor = K.eval(dice_coefficient(liver_tumor_true, liver_tumor_pred))\n",
    "print(\"\\nDice Coefficient for Liver + Tumor combined: {:.4f}\".format(dice_liver_tumor))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Unet++ Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class NestedConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(NestedConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "\n",
    "class UNetPlusPlus2D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3):\n",
    "        super(UNetPlusPlus2D, self).__init__()\n",
    "\n",
    "        # Encoding layers\n",
    "        self.enc1 = NestedConvBlock(in_channels, 64)\n",
    "        self.enc2 = NestedConvBlock(64, 128)\n",
    "        self.enc3 = NestedConvBlock(128, 256)\n",
    "        self.enc4 = NestedConvBlock(256, 512)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        # Decoding layers\n",
    "        self.up3 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.dec3 = NestedConvBlock(512, 256)\n",
    "\n",
    "        self.up2 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.dec2 = NestedConvBlock(256, 128)\n",
    "\n",
    "        self.up1 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.dec1 = NestedConvBlock(128, 64)\n",
    "\n",
    "        # Final output layer (3-channel output)\n",
    "        self.final_conv = nn.Conv2d(64, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        enc1 = self.enc1(x)  \n",
    "        enc2 = self.enc2(self.pool(enc1))  \n",
    "        enc3 = self.enc3(self.pool(enc2))  \n",
    "        enc4 = self.enc4(self.pool(enc3))  \n",
    "\n",
    "        dec3 = self.dec3(torch.cat([self.up3(enc4), enc3], dim=1))  \n",
    "        dec2 = self.dec2(torch.cat([self.up2(dec3), enc2], dim=1))  \n",
    "        dec1 = self.dec1(torch.cat([self.up1(dec2), enc1], dim=1))  \n",
    "\n",
    "        return self.final_conv(dec1)  \n",
    "\n",
    "class UNetPlusPlusSlices(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3):\n",
    "        super(UNetPlusPlusSlices, self).__init__()\n",
    "        self.unet_2d = UNetPlusPlus2D(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:  # If input is [1, 128, 128]\n",
    "            x = x.unsqueeze(0)  # Convert to [1, 1, 128, 128]\n",
    "\n",
    "        out = self.unet_2d(x)  # Process through UNet++\n",
    "        out = out.squeeze(0)  # Remove batch dimension to get [1, 128, 128, 3]\n",
    "\n",
    "        return out\n",
    "\n",
    "# Example usage:\n",
    "model = UNetPlusPlusSlices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "Y_train = torch.tensor(Y_train, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5277, 128, 128]) torch.Size([5277, 128, 128, 3])\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, Y_train.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Define Dice Coefficient (for evaluation)\n",
    "def dice_coefficient(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_flat = y_true.view(-1)\n",
    "    y_pred_flat = y_pred.view(-1)\n",
    "    intersection = (y_true_flat * y_pred_flat).sum()\n",
    "    return (2. * intersection + smooth) / (y_true_flat.sum() + y_pred_flat.sum() + smooth)\n",
    "\n",
    "# Hyperparameters\n",
    "LEARNING_RATE = 0.01\n",
    "EPOCHS = 2\n",
    "BATCH_SIZE = 16  # Adjust batch size as needed\n",
    "LOG_FILE = \"training_log.txt\"  # Log file path\n",
    "\n",
    "# Custom Dataset class\n",
    "class LiverTumorDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x_slice = self.X[idx].unsqueeze(0)  # Shape: [1, 128, 128] (Adding channel dimension)\n",
    "        y_slice = self.Y[idx].argmax(dim=-1)  # Convert one-hot to class labels, Shape: [128, 128]\n",
    "        return x_slice, y_slice\n",
    "\n",
    "# Initialize dataset and dataloader\n",
    "dataset = LiverTumorDataset(X_train, Y_train)\n",
    "dataloader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "model = UNetPlusPlusSlices(in_channels=1, out_channels=3)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # Multi-class segmentation\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "\n",
    "# Open log file for writing\n",
    "with open(LOG_FILE, \"w\") as log_file:\n",
    "    log_file.write(\"Epoch, Batch, Loss\\n\")  # CSV header\n",
    "\n",
    "    # Training loop with batching\n",
    "    for epoch in range(EPOCHS):\n",
    "        model.train()\n",
    "        epoch_loss = 0.0  \n",
    "\n",
    "        for batch_idx, (x_batch, y_batch) in enumerate(dataloader):\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Move data to device\n",
    "            x_batch, y_batch = x_batch.to(device), y_batch.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            output = model(x_batch)  # Expected output: [BATCH_SIZE, 3, 128, 128]\n",
    "\n",
    "            # Compute loss\n",
    "            loss = criterion(output, y_batch)  # Shapes should match now\n",
    "\n",
    "            # Backpropagation\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Write batch loss to log file\n",
    "            log_file.write(f\"{epoch+1}, {batch_idx+1}, {loss.item():.4f}\\n\")\n",
    "\n",
    "            # Print progress every 10 slices\n",
    "            if (batch_idx + 1) % 10 == 0:\n",
    "                print(f\"Epoch {epoch+1}, Batch {batch_idx+1}: Processed {BATCH_SIZE * (batch_idx + 1)} slices\")\n",
    "\n",
    "        avg_loss = epoch_loss / len(dataloader)\n",
    "        print(f\"Epoch [{epoch+1}/{EPOCHS}], Loss: {avg_loss:.4f}\")\n",
    "\n",
    "print(f\"Training complete. Logs saved in {LOG_FILE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'Unet++.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UNetPlusPlusSlices()\n",
    "model.load_state_dict(torch.load('Unet++.pth'))  # Load weights\n",
    "model.eval()  # Set to evaluation mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "Y_test = torch.tensor(Y_test, dtype=torch.long)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "print(sklearn.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, jaccard_score\n",
    "\n",
    "# Dice coefficient\n",
    "def dice_score(y_true, y_pred, smooth=1e-6):\n",
    "    y_true_flat = y_true.flatten()\n",
    "    y_pred_flat = y_pred.flatten()\n",
    "    intersection = np.sum(y_true_flat * y_pred_flat)\n",
    "    return (2. * intersection + smooth) / (np.sum(y_true_flat) + np.sum(y_pred_flat) + smooth)\n",
    "\n",
    "# Custom test dataset for [501, 128, 128, 1] input and [501, 128, 128, 3] label\n",
    "class LiverTumorTestDataset(Dataset):\n",
    "    def __init__(self, X, Y):\n",
    "        self.X = X\n",
    "        self.Y = Y\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.X.shape[0]  # 501 slices\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.X[idx].permute(2, 0, 1).float()  # [1, 128, 128]\n",
    "        y = self.Y[idx].argmax(dim=-1).long()     # [128, 128]\n",
    "        return x, y\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Dataset and DataLoader\n",
    "test_dataset = LiverTumorTestDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False)\n",
    "\n",
    "# Containers for metrics\n",
    "all_preds = []\n",
    "all_trues = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        x = x.to(device)                      # [1, 1, 128, 128]\n",
    "        y = y.squeeze(0).cpu().numpy()        # [128, 128]\n",
    "\n",
    "        output = model(x.squeeze(0))          # [3, 128, 128] assuming model expects [1, 128, 128]\n",
    "        pred = torch.argmax(output, dim=0).cpu().numpy()\n",
    "\n",
    "        all_preds.append(pred)\n",
    "        all_trues.append(y)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "all_preds = np.array(all_preds)  # [501, 128, 128]\n",
    "all_trues = np.array(all_trues)  # [501, 128, 128]\n",
    "\n",
    "# Evaluation metrics per class\n",
    "num_classes = 3\n",
    "for class_idx in range(num_classes):\n",
    "    print(f\"\\nMetrics for Class {class_idx}:\")\n",
    "    y_true_class = (all_trues == class_idx).astype(np.uint8).flatten()\n",
    "    y_pred_class = (all_preds == class_idx).astype(np.uint8).flatten()\n",
    "\n",
    "    iou = jaccard_score(y_true_class, y_pred_class, zero_division=0)\n",
    "    prec = precision_score(y_true_class, y_pred_class, zero_division=0)\n",
    "    rec = recall_score(y_true_class, y_pred_class, zero_division=0)\n",
    "    f1 = f1_score(y_true_class, y_pred_class, zero_division=0)\n",
    "    dice = dice_score(y_true_class, y_pred_class)\n",
    "\n",
    "    print(f\"IoU: {iou:.4f}\")\n",
    "    print(f\"Precision: {prec:.4f}\")\n",
    "    print(f\"Recall: {rec:.4f}\")\n",
    "    print(f\"F1-score: {f1:.4f}\")\n",
    "    print(f\"Dice Coefficient: {dice:.4f}\")\n",
    "\n",
    "# Combined liver + tumor (class 1 + 2)\n",
    "combined_true = ((all_trues == 1) | (all_trues == 2)).astype(np.uint8).flatten()\n",
    "combined_pred = ((all_preds == 1) | (all_preds == 2)).astype(np.uint8).flatten()\n",
    "combined_dice = dice_score(combined_true, combined_pred)\n",
    "print(\"\\nDice Coefficient for Liver + Tumor combined: {:.4f}\".format(combined_dice))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def display_predictions(X_test, y_true_labels, y_pred_labels, num_samples=5, start_idx=0):\n",
    "    \"\"\"\n",
    "    Visualizes predictions for given number of slices.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_test: input test images [N, 128, 128, 1]\n",
    "    - y_true_labels: ground truth class labels [N, 128, 128]\n",
    "    - y_pred_labels: predicted class labels [N, 128, 128]\n",
    "    - num_samples: how many slices to display\n",
    "    - start_idx: from which slice index to start\n",
    "    \"\"\"\n",
    "    for i in range(start_idx, start_idx + num_samples):\n",
    "        plt.figure(figsize=(12, 4))\n",
    "\n",
    "        # Input slice\n",
    "        plt.subplot(1, 3, 1)\n",
    "        plt.imshow(X_test[i, :, :, 0], cmap='gray')\n",
    "        plt.title(f\"Input Slice {i}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Ground truth mask\n",
    "        plt.subplot(1, 3, 2)\n",
    "        plt.imshow(y_true_labels[i], cmap='jet', vmin=0, vmax=2)\n",
    "        plt.title(\"Ground Truth\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Predicted mask\n",
    "        plt.subplot(1, 3, 3)\n",
    "        plt.imshow(y_pred_labels[i], cmap='jet', vmin=0, vmax=2)\n",
    "        plt.title(\"Predicted Mask\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# Example: Display first 5 slices\n",
    "display_predictions(X_test, y_true_labels, y_pred_labels, num_samples=5, start_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer Based Model Architecture\n",
    "Patch Embedding: Flatten image into patches + linear projection.\n",
    "\n",
    "Transformer Encoder: Several layers of Multi-head Self Attention + Feed-Forward.\n",
    "\n",
    "Decoder: Upsample tokens to the original image resolution.\n",
    "\n",
    "Final Conv Layer: To get output with 3 channels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class PatchEmbedding(nn.Module):\n",
    "    def __init__(self, in_channels=1, embed_dim=256, patch_size=16):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.proj = nn.Conv2d(in_channels, embed_dim, kernel_size=patch_size, stride=patch_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)  # [B, embed_dim, H/patch, W/patch]\n",
    "        x = x.flatten(2).transpose(1, 2)  # [B, N_patches, embed_dim]\n",
    "        return x\n",
    "\n",
    "class TransformerEncoderBlock(nn.Module):\n",
    "    def __init__(self, embed_dim=256, num_heads=8, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.norm1 = nn.LayerNorm(embed_dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim, num_heads, dropout=dropout, batch_first=True)\n",
    "        self.norm2 = nn.LayerNorm(embed_dim)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(embed_dim, embed_dim * 4),\n",
    "            nn.GELU(),\n",
    "            nn.Linear(embed_dim * 4, embed_dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x + self.attn(self.norm1(x), self.norm1(x), self.norm1(x))[0]\n",
    "        x = x + self.ff(self.norm2(x))\n",
    "        return x\n",
    "\n",
    "class TransformerDecoder(nn.Module):\n",
    "    def __init__(self, embed_dim=256, patch_size=16, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.patch_size = patch_size\n",
    "        self.output_proj = nn.Linear(embed_dim, patch_size * patch_size * out_channels)\n",
    "\n",
    "    def forward(self, x, h, w):\n",
    "        x = self.output_proj(x)  # [B, N, P*P*out_channels]\n",
    "        x = x.view(x.size(0), h, w, self.patch_size, self.patch_size, -1)\n",
    "        x = x.permute(0, 5, 1, 3, 2, 4).contiguous()  # [B, out_channels, H, P, W, P]\n",
    "        x = x.view(x.size(0), -1, h * self.patch_size, w * self.patch_size)  # [B, C, H*P, W*P]\n",
    "        return x\n",
    "\n",
    "class TransformerSegmentationModel(nn.Module):\n",
    "    def __init__(self, img_size=128, patch_size=16, in_channels=1, out_channels=3, embed_dim=256, depth=4, num_heads=8):\n",
    "        super().__init__()\n",
    "        self.patch_embed = PatchEmbedding(in_channels, embed_dim, patch_size)\n",
    "        self.encoder = nn.Sequential(\n",
    "            *[TransformerEncoderBlock(embed_dim, num_heads) for _ in range(depth)]\n",
    "        )\n",
    "        self.decoder = TransformerDecoder(embed_dim, patch_size, out_channels)\n",
    "        self.h = img_size // patch_size\n",
    "        self.w = img_size // patch_size\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0)  # [1, 1, H, W]\n",
    "        x = self.patch_embed(x)\n",
    "        x = self.encoder(x)\n",
    "        out = self.decoder(x, self.h, self.w)\n",
    "        return out  # [B, 3, 128, 128]\n",
    "\n",
    "\n",
    "class TransformerSegmentationSlices(nn.Module):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = TransformerSegmentationModel(**kwargs)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0)  # [1, 1, 128, 128]\n",
    "        return self.model(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is a NNUnet Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm2d(out_ch),\n",
    "            nn.LeakyReLU(inplace=True),\n",
    "            nn.Conv2d(out_ch, out_ch, 3, padding=1),\n",
    "            nn.InstanceNorm2d(out_ch),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Down(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Down, self).__init__()\n",
    "        self.block = nn.Sequential(\n",
    "            nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=2, padding=1),  # strided conv\n",
    "            nn.InstanceNorm2d(out_ch),\n",
    "            nn.LeakyReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.block(x)\n",
    "\n",
    "class Up(nn.Module):\n",
    "    def __init__(self, in_ch, out_ch):\n",
    "        super(Up, self).__init__()\n",
    "        self.up = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=2, stride=2)\n",
    "        self.conv = ConvBlock(in_ch, out_ch)\n",
    "\n",
    "    def forward(self, x1, x2):\n",
    "        x1 = self.up(x1)\n",
    "        # Ensure size match\n",
    "        diffY = x2.size()[2] - x1.size()[2]\n",
    "        diffX = x2.size()[3] - x1.size()[3]\n",
    "        x1 = F.pad(x1, [diffX // 2, diffX - diffX // 2,\n",
    "                        diffY // 2, diffY - diffY // 2])\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        return self.conv(x)\n",
    "\n",
    "class NnUNetLike2D(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3):\n",
    "        super(NnUNetLike2D, self).__init__()\n",
    "\n",
    "        self.inc = ConvBlock(in_channels, 32)\n",
    "        self.down1 = Down(32, 64)\n",
    "        self.conv1 = ConvBlock(64, 64)\n",
    "\n",
    "        self.down2 = Down(64, 128)\n",
    "        self.conv2 = ConvBlock(128, 128)\n",
    "\n",
    "        self.down3 = Down(128, 256)\n",
    "        self.conv3 = ConvBlock(256, 256)\n",
    "\n",
    "        self.up2 = Up(256, 128)\n",
    "        self.up1 = Up(128, 64)\n",
    "        self.up0 = Up(64, 32)\n",
    "\n",
    "        self.out_conv = nn.Conv2d(32, out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = self.inc(x)\n",
    "        x2 = self.conv1(self.down1(x1))\n",
    "        x3 = self.conv2(self.down2(x2))\n",
    "        x4 = self.conv3(self.down3(x3))\n",
    "\n",
    "        x = self.up2(x4, x3)\n",
    "        x = self.up1(x, x2)\n",
    "        x = self.up0(x, x1)\n",
    "        out = self.out_conv(x)\n",
    "        return out\n",
    "\n",
    "class NnUNetSlices(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3):\n",
    "        super().__init__()\n",
    "        self.model = NnUNetLike2D(in_channels, out_channels)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if x.dim() == 3:\n",
    "            x = x.unsqueeze(0)  # [1, 1, H, W]\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Meta-Ensemble / Stacking\n",
    "Use both model outputs as input features to train another model (like a shallow CNN or MLP).\n",
    "\n",
    "This meta-model learns how to best combine their predictions.\n",
    "\n",
    "Requires training a third model → better generalization but more complex."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (myenv)",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
