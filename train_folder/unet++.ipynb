{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore # type: ignore\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "print(torch.__version__)\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOLUME_DIR = \"Dataset/volume_pt1\" \n",
    "SEGMENTATION_DIR = \"Dataset/volume_pt1/segementation\"\n",
    "IMG_SIZE = (128, 128) \n",
    "\n",
    "def load_nifti(file_path):\n",
    "    \"\"\"Load a NIfTI file and return the NumPy array\"\"\"\n",
    "    print(f\"Loading file: {file_path}\") \n",
    "    nifti_img = nib.load(file_path) \n",
    "    return nifti_img.get_fdata()\n",
    "\n",
    "def preprocess_data(volume_path, segmentation_path):\n",
    "    \"\"\"Load and preprocess volume and segmentation data\"\"\"\n",
    "    volume_data = load_nifti(volume_path)\n",
    "    segmentation_data = load_nifti(segmentation_path).astype(int)\n",
    "\n",
    "    volume_data = (volume_data - np.min(volume_data)) / (np.max(volume_data) - np.min(volume_data))\n",
    "\n",
    "    volume_resized = np.array([resize(slice, IMG_SIZE, mode='constant', preserve_range=True) for slice in volume_data.transpose(2, 0, 1)])\n",
    "    segmentation_resized = np.array([resize(slice, IMG_SIZE, mode='constant', preserve_range=True, order=0) for slice in segmentation_data.transpose(2, 0, 1)])\n",
    "\n",
    "   \n",
    "    segmentation_onehot = to_categorical(segmentation_resized, num_classes=3)\n",
    "\n",
    "    return volume_resized, segmentation_onehot\n",
    "\n",
    "\n",
    "X_train, Y_train = [], []\n",
    "\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(VOLUME_DIR) if f.endswith(\".nii\")])\n",
    "mask_files = sorted([f for f in os.listdir(SEGMENTATION_DIR) if f.endswith(\".nii\")])\n",
    "\n",
    "for img_file, mask_file in zip(image_files, mask_files):\n",
    "    volume_path = os.path.join(VOLUME_DIR, img_file)\n",
    "    segmentation_path = os.path.join(SEGMENTATION_DIR, mask_file)\n",
    "    vol, seg = preprocess_data(volume_path, segmentation_path)\n",
    "    X_train.append(vol)\n",
    "    Y_train.append(seg)\n",
    "# Shape: (num_slices, 128, 128)\n",
    "# Shape: (num_slices, 128, 128, 3)\n",
    "X_train = np.concatenate(X_train, axis=0)  \n",
    "Y_train = np.concatenate(Y_train, axis=0)  \n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Segmentation mask shape:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "# Function to load NIfTI files\n",
    "def load_nifti(file_path):\n",
    "    \"\"\"Load a NIfTI file and return the NumPy array\"\"\"\n",
    "    print(f\"Loading: {file_path}\")  # Debugging: Print file being loaded\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    nifti_img = nib.load(file_path)\n",
    "    return nifti_img.get_fdata()\n",
    "\n",
    "# Function to preprocess test data\n",
    "def preprocess_data(test_volume_path, test_segmentation_path):\n",
    "    \"\"\"Load and preprocess a single test volume and its corresponding segmentation mask\"\"\"\n",
    "    volume_data = load_nifti(test_volume_path)\n",
    "    segmentation_data = load_nifti(test_segmentation_path).astype(int)\n",
    "\n",
    "    # Normalize CT images (0-1)\n",
    "    volume_data = (volume_data - np.min(volume_data)) / (np.max(volume_data) - np.min(volume_data))\n",
    "\n",
    "    # Resize to (128, 128)\n",
    "    from skimage.transform import resize\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    volume_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True)\n",
    "        for slice in volume_data.transpose(2, 0, 1)  # Rearrange to (slices, H, W)\n",
    "    ])\n",
    "    \n",
    "    segmentation_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True, order=0) \n",
    "        for slice in segmentation_data.transpose(2, 0, 1)\n",
    "    ])\n",
    "\n",
    "    # One-hot encode segmentation masks (background=0, liver=1, tumor=2)\n",
    "    \n",
    "    segmentation_onehot = to_categorical(segmentation_resized, num_classes=3)\n",
    "\n",
    "    return volume_resized, segmentation_onehot\n",
    "\n",
    "# ---- Load Test Data ----\n",
    "test_image_path = os.path.join(\"test_folder\") \n",
    "test_mask_path = os.path.join(\"test_folder\", \"segmentation\") \n",
    "\n",
    "# Ensure directories exist\n",
    "if not os.path.exists(test_image_path) or not os.path.exists(test_mask_path):\n",
    "    raise FileNotFoundError(\"Test data folder or segmentation folder not found!\")\n",
    "\n",
    "# Get sorted filenames\n",
    "image_files = sorted([f for f in os.listdir(test_image_path) if f.endswith(\".nii\")])\n",
    "mask_files = sorted([f for f in os.listdir(test_mask_path) if f.endswith(\".nii\")])\n",
    "\n",
    "# Check if the number of images and masks match\n",
    "if len(image_files) != len(mask_files):\n",
    "    raise ValueError(\"Mismatch between the number of test images and segmentation masks!\")\n",
    "\n",
    "X_test, Y_test = [], []\n",
    "\n",
    "# Load and preprocess each test image and mask\n",
    "for img_file, mask_file in zip(image_files, mask_files):\n",
    "    volume_path = os.path.join(test_image_path, img_file)  # Correct path joining\n",
    "    segmentation_path = os.path.join(test_mask_path, mask_file)  # Correct path joining\n",
    "\n",
    "    vol, seg = preprocess_data(volume_path, segmentation_path)\n",
    "    X_test.append(vol)\n",
    "    Y_test.append(seg)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_test = np.array(X_test)  # Shape: (num_volumes, num_slices, 128, 128)\n",
    "Y_test = np.array(Y_test)  # Shape: (num_volumes, num_slices, 128, 128, 3)\n",
    "\n",
    "# Reshape to flatten across all slices\n",
    "X_test = X_test.reshape(-1, 128, 128, 1)  # Add channel dimension\n",
    "Y_test = Y_test.reshape(-1, 128, 128, 3)  # Keep segmentation masks in one-hot format\n",
    "\n",
    "# Print shapes\n",
    "print(\"Final Test Data Shape:\", X_test.shape)  # (total_slices, 128, 128, 1)\n",
    "print(\"Final Test Mask Shape:\", Y_test.shape)  # (total_slices, 128, 128, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# 3. Define the UNet++ model (same as in your original message)\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, filters=[32, 64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.conv0_0 = ConvBlock(in_channels, filters[0])\n",
    "        self.pool0 = nn.MaxPool2d(2)\n",
    "        self.conv1_0 = ConvBlock(filters[0], filters[1])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2_0 = ConvBlock(filters[1], filters[2])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3_0 = ConvBlock(filters[2], filters[3])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4_0 = ConvBlock(filters[3], filters[4])\n",
    "\n",
    "        self.up1_0 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.conv0_1 = ConvBlock(filters[0]*2, filters[0])\n",
    "        self.up2_0 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.conv1_1 = ConvBlock(filters[1]*2, filters[1])\n",
    "        self.up3_0 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.conv2_1 = ConvBlock(filters[2]*2, filters[2])\n",
    "        self.up4_0 = nn.ConvTranspose2d(filters[4], filters[3], kernel_size=2, stride=2)\n",
    "        self.conv3_1 = ConvBlock(filters[3]*2, filters[3])\n",
    "\n",
    "        self.up1_1 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.conv0_2 = ConvBlock(filters[0]*3, filters[0])\n",
    "        self.up2_1 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.conv1_2 = ConvBlock(filters[1]*3, filters[1])\n",
    "        self.up3_1 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.conv2_2 = ConvBlock(filters[2]*3, filters[2])\n",
    "\n",
    "        self.final_conv = nn.Conv2d(filters[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool0(x0_0))\n",
    "        x2_0 = self.conv2_0(self.pool1(x1_0))\n",
    "        x3_0 = self.conv3_0(self.pool2(x2_0))\n",
    "        x4_0 = self.conv4_0(self.pool3(x3_0))\n",
    "\n",
    "        x3_1 = self.conv3_1(torch.cat([self.up4_0(x4_0), x3_0], 1))\n",
    "        x2_1 = self.conv2_1(torch.cat([self.up3_0(x3_0), x2_0], 1))\n",
    "        x1_1 = self.conv1_1(torch.cat([self.up2_0(x2_0), x1_0], 1))\n",
    "        x0_1 = self.conv0_1(torch.cat([self.up1_0(x1_0), x0_0], 1))\n",
    "\n",
    "        x2_2 = self.conv2_2(torch.cat([self.up3_1(x3_1), x2_0, x2_1], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([self.up2_1(x2_1), x1_0, x1_1], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([self.up1_1(x1_1), x0_0, x0_1], 1))\n",
    "\n",
    "        return self.final_conv(x0_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data to tensors\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32).unsqueeze(1)  # (N, 1, 128, 128)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.float32).permute(0, 3, 1, 2)  # (N, 3, 128, 128)\n",
    "\n",
    "# Create a DataLoader with all slices in one batch\n",
    "test_dataset = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "test_loader = DataLoader(test_dataset, batch_size=len(test_dataset), shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training Setup\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model = UNetPlusPlus().to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# 5. Training Loop\n",
    "num_epochs = 15\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    epoch_loss = 0.0\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "        targets = torch.argmax(targets, dim=1)  # Convert one-hot to class indices\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(y_true, y_pred, num_classes=3):\n",
    "    smooth = 1e-6\n",
    "    metrics = {}\n",
    "\n",
    "    for cls in range(num_classes):\n",
    "        y_true_cls = (y_true == cls)\n",
    "        y_pred_cls = (y_pred == cls)\n",
    "\n",
    "        intersection = (y_true_cls & y_pred_cls).sum().item()\n",
    "        union = (y_true_cls | y_pred_cls).sum().item()\n",
    "        tp = intersection\n",
    "        fp = y_pred_cls.sum().item() - tp\n",
    "        fn = y_true_cls.sum().item() - tp\n",
    "\n",
    "        precision = tp / (tp + fp + smooth)\n",
    "        recall = tp / (tp + fn + smooth)\n",
    "        f1 = 2 * precision * recall / (precision + recall + smooth)\n",
    "        iou = intersection / (union + smooth)\n",
    "        dice = 2 * intersection / (y_pred_cls.sum().item() + y_true_cls.sum().item() + smooth)\n",
    "\n",
    "        metrics[cls] = {\n",
    "            'IoU': iou,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1-score': f1,\n",
    "            'Dice': dice\n",
    "        }\n",
    "\n",
    "    # Dice for class 1 + class 2 (liver + tumor)\n",
    "    liver = (y_true == 1)\n",
    "    tumor = (y_true == 2)\n",
    "    pred_liver = (y_pred == 1)\n",
    "    pred_tumor = (y_pred == 2)\n",
    "\n",
    "    combined_true = liver | tumor\n",
    "    combined_pred = pred_liver | pred_tumor\n",
    "    intersection = (combined_true & combined_pred).sum().item()\n",
    "    dice_combined = 2 * intersection / (combined_true.sum().item() + combined_pred.sum().item() + smooth)\n",
    "\n",
    "    return metrics, dice_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        outputs = model(inputs)\n",
    "        predictions = torch.argmax(outputs, dim=1)  # (N, 128, 128)\n",
    "        true_classes = torch.argmax(targets, dim=1)  # (N, 128, 128)\n",
    "\n",
    "metrics, dice_combined = compute_metrics(true_classes.cpu(), predictions.cpu())\n",
    "\n",
    "# Print all class-wise metrics\n",
    "for cls in metrics:\n",
    "    print(f\"Metrics for Class {cls}:\")\n",
    "    print(f\"IoU: {metrics[cls]['IoU']:.4f}\")\n",
    "    print(f\"Precision: {metrics[cls]['Precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics[cls]['Recall']:.4f}\")\n",
    "    print(f\"F1-score: {metrics[cls]['F1-score']:.4f}\")\n",
    "    print(f\"Dice Coefficient: {metrics[cls]['Dice']:.4f}\\n\")\n",
    "\n",
    "print(f\"Dice Coefficient for Liver + Tumor combined: {dice_combined:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
