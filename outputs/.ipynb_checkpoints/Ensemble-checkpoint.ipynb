{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import nibabel as nib\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore # type: ignore\n",
    "from skimage.transform import resize\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2.3\n",
      "2.0.2\n",
      "2.18.0\n",
      "2.6.0+cpu\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(pd.__version__)\n",
    "print(np.__version__)\n",
    "print(tf.__version__)\n",
    "print(torch.__version__)\n",
    "print(\"GPU is\", \"available\" if torch.cuda.is_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading file: train_folder\\volume-0.nii\n",
      "Loading file: train_folder\\Segmentation\\segmentation-0.nii\n",
      "Loading file: train_folder\\volume-1.nii\n",
      "Loading file: train_folder\\Segmentation\\segmentation-1.nii\n",
      "Loading file: train_folder\\volume-2.nii\n",
      "Loading file: train_folder\\Segmentation\\segmentation-2.nii\n",
      "Loading file: train_folder\\volume-3.nii\n",
      "Loading file: train_folder\\Segmentation\\segmentation-3.nii\n",
      "Loading file: train_folder\\volume-4.nii\n",
      "Loading file: train_folder\\Segmentation\\segmentation-4.nii\n",
      "Training data shape: (2090, 128, 128)\n",
      "Segmentation mask shape: (2090, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "VOLUME_DIR = \"train_folder\"\n",
    "SEGMENTATION_DIR = os.path.join(\"train_folder\", \"Segmentation\")\n",
    "IMG_SIZE = (128, 128)\n",
    "\n",
    "def load_nifti(file_path):\n",
    "    \"\"\"Load a NIfTI file and return the NumPy array\"\"\"\n",
    "    print(f\"Loading file: {file_path}\") \n",
    "    nifti_img = nib.load(file_path) \n",
    "    return nifti_img.get_fdata()\n",
    "\n",
    "def preprocess_data(volume_path, segmentation_path):\n",
    "    \"\"\"Load and preprocess volume and segmentation data\"\"\"\n",
    "    volume_data = load_nifti(volume_path)\n",
    "    segmentation_data = load_nifti(segmentation_path).astype(int)\n",
    "\n",
    "    volume_data = (volume_data - np.min(volume_data)) / (np.max(volume_data) - np.min(volume_data))\n",
    "\n",
    "    volume_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True) \n",
    "        for slice in volume_data.transpose(2, 0, 1)\n",
    "    ])\n",
    "    segmentation_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True, order=0) \n",
    "        for slice in segmentation_data.transpose(2, 0, 1)\n",
    "    ])\n",
    "\n",
    "    segmentation_onehot = to_categorical(segmentation_resized, num_classes=3)\n",
    "\n",
    "    return volume_resized, segmentation_onehot\n",
    "\n",
    "X_train, Y_train = [], []\n",
    "\n",
    "image_files = sorted([f for f in os.listdir(VOLUME_DIR) if f.endswith(\".nii\")])\n",
    "mask_files = sorted([f for f in os.listdir(SEGMENTATION_DIR) if f.endswith(\".nii\")])\n",
    "\n",
    "for img_file, mask_file in zip(image_files, mask_files):\n",
    "    volume_path = os.path.join(VOLUME_DIR, img_file)\n",
    "    segmentation_path = os.path.join(SEGMENTATION_DIR, mask_file)\n",
    "    vol, seg = preprocess_data(volume_path, segmentation_path)\n",
    "    X_train.append(vol)\n",
    "    Y_train.append(seg)\n",
    "\n",
    "X_train = np.concatenate(X_train, axis=0)\n",
    "Y_train = np.concatenate(Y_train, axis=0)\n",
    "\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Segmentation mask shape:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading: test_folder\\volume-10.nii\n",
      "Loading: test_folder\\segmentation\\segmentation-10.nii\n",
      "Final Test Data Shape: (501, 128, 128, 1)\n",
      "Final Test Mask Shape: (501, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import nibabel as nib\n",
    "from tensorflow.keras.utils import to_categorical # type: ignore\n",
    "# Function to load NIfTI files\n",
    "def load_nifti(file_path):\n",
    "    \"\"\"Load a NIfTI file and return the NumPy array\"\"\"\n",
    "    print(f\"Loading: {file_path}\")  # Debugging: Print file being loaded\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"File not found: {file_path}\")\n",
    "    \n",
    "    nifti_img = nib.load(file_path)\n",
    "    return nifti_img.get_fdata()\n",
    "\n",
    "# Function to preprocess test data\n",
    "def preprocess_data(test_volume_path, test_segmentation_path):\n",
    "    \"\"\"Load and preprocess a single test volume and its corresponding segmentation mask\"\"\"\n",
    "    volume_data = load_nifti(test_volume_path)\n",
    "    segmentation_data = load_nifti(test_segmentation_path).astype(int)\n",
    "\n",
    "    # Normalize CT images (0-1)\n",
    "    volume_data = (volume_data - np.min(volume_data)) / (np.max(volume_data) - np.min(volume_data))\n",
    "\n",
    "    # Resize to (128, 128)\n",
    "    from skimage.transform import resize\n",
    "    IMG_SIZE = (128, 128)\n",
    "    \n",
    "    volume_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True)\n",
    "        for slice in volume_data.transpose(2, 0, 1)  # Rearrange to (slices, H, W)\n",
    "    ])\n",
    "    \n",
    "    segmentation_resized = np.array([\n",
    "        resize(slice, IMG_SIZE, mode='constant', preserve_range=True, order=0) \n",
    "        for slice in segmentation_data.transpose(2, 0, 1)\n",
    "    ])\n",
    "\n",
    "    # One-hot encode segmentation masks (background=0, liver=1, tumor=2)\n",
    "    \n",
    "    segmentation_onehot = to_categorical(segmentation_resized, num_classes=3)\n",
    "\n",
    "    return volume_resized, segmentation_onehot\n",
    "\n",
    "# ---- Load Test Data ----\n",
    "test_image_path = os.path.join(\"test_folder\") \n",
    "test_mask_path = os.path.join(\"test_folder\", \"segmentation\") \n",
    "\n",
    "# Ensure directories exist\n",
    "if not os.path.exists(test_image_path) or not os.path.exists(test_mask_path):\n",
    "    raise FileNotFoundError(\"Test data folder or segmentation folder not found!\")\n",
    "\n",
    "# Get sorted filenames\n",
    "image_files = sorted([f for f in os.listdir(test_image_path) if f.endswith(\".nii\")])\n",
    "mask_files = sorted([f for f in os.listdir(test_mask_path) if f.endswith(\".nii\")])\n",
    "\n",
    "# Check if the number of images and masks match\n",
    "if len(image_files) != len(mask_files):\n",
    "    raise ValueError(\"Mismatch between the number of test images and segmentation masks!\")\n",
    "\n",
    "X_test, Y_test = [], []\n",
    "\n",
    "# Load and preprocess each test image and mask\n",
    "for img_file, mask_file in zip(image_files, mask_files):\n",
    "    volume_path = os.path.join(test_image_path, img_file)  # Correct path joining\n",
    "    segmentation_path = os.path.join(test_mask_path, mask_file)  # Correct path joining\n",
    "\n",
    "    vol, seg = preprocess_data(volume_path, segmentation_path)\n",
    "    X_test.append(vol)\n",
    "    Y_test.append(seg)\n",
    "\n",
    "# Convert lists to NumPy arrays\n",
    "X_test = np.array(X_test)  # Shape: (num_volumes, num_slices, 128, 128)\n",
    "Y_test = np.array(Y_test)  # Shape: (num_volumes, num_slices, 128, 128, 3)\n",
    "\n",
    "# Reshape to flatten across all slices\n",
    "X_test = X_test.reshape(-1, 128, 128, 1)  # Add channel dimension\n",
    "Y_test = Y_test.reshape(-1, 128, 128, 3)  # Keep segmentation masks in one-hot format\n",
    "\n",
    "# Print shapes\n",
    "print(\"Final Test Data Shape:\", X_test.shape)  # (total_slices, 128, 128, 1)\n",
    "print(\"Final Test Mask Shape:\", Y_test.shape)  # (total_slices, 128, 128, 3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "# 3. Define the UNet++ model (same as in your original message)\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.double_conv = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, 3, padding=1),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.double_conv(x)\n",
    "\n",
    "class UNetPlusPlus(nn.Module):\n",
    "    def __init__(self, in_channels=1, out_channels=3, filters=[32, 64, 128, 256, 512]):\n",
    "        super().__init__()\n",
    "        self.conv0_0 = ConvBlock(in_channels, filters[0])\n",
    "        self.pool0 = nn.MaxPool2d(2)\n",
    "        self.conv1_0 = ConvBlock(filters[0], filters[1])\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.conv2_0 = ConvBlock(filters[1], filters[2])\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.conv3_0 = ConvBlock(filters[2], filters[3])\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.conv4_0 = ConvBlock(filters[3], filters[4])\n",
    "\n",
    "        self.up1_0 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.conv0_1 = ConvBlock(filters[0]*2, filters[0])\n",
    "        self.up2_0 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.conv1_1 = ConvBlock(filters[1]*2, filters[1])\n",
    "        self.up3_0 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.conv2_1 = ConvBlock(filters[2]*2, filters[2])\n",
    "        self.up4_0 = nn.ConvTranspose2d(filters[4], filters[3], kernel_size=2, stride=2)\n",
    "        self.conv3_1 = ConvBlock(filters[3]*2, filters[3])\n",
    "\n",
    "        self.up1_1 = nn.ConvTranspose2d(filters[1], filters[0], kernel_size=2, stride=2)\n",
    "        self.conv0_2 = ConvBlock(filters[0]*3, filters[0])\n",
    "        self.up2_1 = nn.ConvTranspose2d(filters[2], filters[1], kernel_size=2, stride=2)\n",
    "        self.conv1_2 = ConvBlock(filters[1]*3, filters[1])\n",
    "        self.up3_1 = nn.ConvTranspose2d(filters[3], filters[2], kernel_size=2, stride=2)\n",
    "        self.conv2_2 = ConvBlock(filters[2]*3, filters[2])\n",
    "\n",
    "        self.final_conv = nn.Conv2d(filters[0], out_channels, kernel_size=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x0_0 = self.conv0_0(x)\n",
    "        x1_0 = self.conv1_0(self.pool0(x0_0))\n",
    "        x2_0 = self.conv2_0(self.pool1(x1_0))\n",
    "        x3_0 = self.conv3_0(self.pool2(x2_0))\n",
    "        x4_0 = self.conv4_0(self.pool3(x3_0))\n",
    "\n",
    "        x3_1 = self.conv3_1(torch.cat([self.up4_0(x4_0), x3_0], 1))\n",
    "        x2_1 = self.conv2_1(torch.cat([self.up3_0(x3_0), x2_0], 1))\n",
    "        x1_1 = self.conv1_1(torch.cat([self.up2_0(x2_0), x1_0], 1))\n",
    "        x0_1 = self.conv0_1(torch.cat([self.up1_0(x1_0), x0_0], 1))\n",
    "\n",
    "        x2_2 = self.conv2_2(torch.cat([self.up3_1(x3_1), x2_0, x2_1], 1))\n",
    "        x1_2 = self.conv1_2(torch.cat([self.up2_1(x2_1), x1_0, x1_1], 1))\n",
    "        x0_2 = self.conv0_2(torch.cat([self.up1_1(x1_1), x0_0, x0_1], 1))\n",
    "\n",
    "        return self.final_conv(x0_2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# Assuming x_train is (2090, 128, 128) and y_train is (2090, 128, 128, 3)\n",
    "class SliceDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        # Convert to float32 and torch tensors\n",
    "        self.x = torch.tensor(x, dtype=torch.float32).unsqueeze(1)  # (N, 1, 128, 128)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).permute(0, 3, 1, 2)  # (N, 3, 128, 128)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Create dataset and loader\n",
    "batch_size = 16\n",
    "dataset = SliceDataset(X_train, Y_train)\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Images shape: torch.Size([16, 1, 128, 128])\n",
      "✅ Masks shape: torch.Size([16, 3, 128, 128])\n",
      "Image min/max: 0.0 0.8922176957130432\n",
      "Mask unique values (flattened): tensor([0., 1.])\n",
      "Is one-hot encoded? True\n",
      "Batch 1\n",
      "Image batch shape: torch.Size([16, 1, 128, 128])\n",
      "Mask batch shape: torch.Size([16, 3, 128, 128])\n",
      "Model output shape: torch.Size([16, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "# Fetch one batch from the DataLoader and print details\n",
    "for images, masks in train_loader:\n",
    "    print(\"✅ Images shape:\", images.shape)  # Should be (16, 1, 128, 128)\n",
    "    print(\"✅ Masks shape:\", masks.shape)    # Should be (16, 3, 128, 128)\n",
    "    \n",
    "    # Check value ranges\n",
    "    print(\"Image min/max:\", images.min().item(), images.max().item())\n",
    "    print(\"Mask unique values (flattened):\", torch.unique(masks))\n",
    "\n",
    "    # Optional: check one-hot encoding validity\n",
    "    is_one_hot = torch.all((masks.sum(dim=1) == 1) | (masks.sum(dim=1) == 0))\n",
    "    print(\"Is one-hot encoded?\", is_one_hot.item())\n",
    "\n",
    "    break  # Just check the first batch\n",
    "\n",
    "# Test DataLoader\n",
    "for batch_idx, (images, masks) in enumerate(train_loader):\n",
    "    print(f\"Batch {batch_idx + 1}\")\n",
    "    print(f\"Image batch shape: {images.shape}\")  # Should be (16, 1, 128, 128)\n",
    "    print(f\"Mask batch shape: {masks.shape}\")    # Should be (16, 3, 128, 128)\n",
    "    \n",
    "    # Optionally test forward pass through your model\n",
    "    model = UNetPlusPlus(in_channels=1, out_channels=3)  # Ensure model is defined\n",
    "    outputs = model(images)  # Forward pass\n",
    "    print(f\"Model output shape: {outputs.shape}\")  # Should be (16, 3, 128, 128)\n",
    "    \n",
    "    break  # Just check one batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Test Data Shape: (501, 128, 128)\n",
      "Final Test Mask Shape: (501, 128, 128, 3)\n",
      "Training data shape: (2090, 128, 128)\n",
      "Segmentation mask shape: (2090, 128, 128, 3)\n"
     ]
    }
   ],
   "source": [
    "# Print shapes\n",
    "X_test = np.squeeze(X_test, axis=-1)  # Now shape: (501, 128, 128)\n",
    "print(\"Final Test Data Shape:\", X_test.shape)  # (total_slices, 128, 128, 1)\n",
    "print(\"Final Test Mask Shape:\", Y_test.shape)  # (total_slices, 128, 128, 3)\n",
    "print(\"Training data shape:\", X_train.shape)\n",
    "print(\"Segmentation mask shape:\", Y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fixed input shape: torch.Size([16, 1, 128, 128])\n",
      "Fixed mask shape: torch.Size([16, 3, 128, 128])\n",
      "Model output shape: torch.Size([16, 3, 128, 128])\n"
     ]
    }
   ],
   "source": [
    "class TestSliceDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        super().__init__()\n",
    "        # Remove the last dimension if it's singleton (1)\n",
    "        if x.shape[-1] == 1:\n",
    "            x = np.squeeze(x, axis=-1)  # Now (N, 128, 128)\n",
    "\n",
    "        self.x = torch.tensor(x, dtype=torch.float32).unsqueeze(1)  # (N, 1, 128, 128)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32).permute(0, 3, 1, 2)  # (N, 3, 128, 128)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "# Use it\n",
    "test_dataset = TestSliceDataset(X_test, Y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "for images, masks in test_loader:\n",
    "    print(\"Fixed input shape:\", images.shape)  # ✅ Should be (16, 1, 128, 128)\n",
    "    print(\"Fixed mask shape:\", masks.shape)    # ✅ Should be (16, 3, 128, 128)\n",
    "    \n",
    "    # Forward pass\n",
    "    outputs = model(images)\n",
    "    print(\"Model output shape:\", outputs.shape)\n",
    "    break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 4. Training Setup\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# model = UNetPlusPlus().to(device)\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# # 5. Training Loop\n",
    "# num_epochs = 15\n",
    "# for epoch in range(num_epochs):\n",
    "#     model.train()\n",
    "#     epoch_loss = 0.0\n",
    "#     for inputs, targets in train_loader:\n",
    "#         inputs = inputs.to(device)\n",
    "#         targets = targets.to(device)\n",
    "#         targets = torch.argmax(targets, dim=1)  # Convert one-hot to class indices\n",
    "\n",
    "#         outputs = model(inputs)\n",
    "#         loss = criterion(outputs, targets)\n",
    "\n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "#         epoch_loss += loss.item()\n",
    "\n",
    "#     print(f\"Epoch [{epoch+1}/{num_epochs}] Loss: {epoch_loss / len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "UNetPlusPlus(\n",
       "  (conv0_0): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool0): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv1_0): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2_0): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv3_0): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv4_0): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up1_0): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv0_1): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up2_0): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv1_1): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up3_0): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv2_1): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up4_0): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv3_1): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up1_1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv0_2): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up2_1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv1_2): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(192, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (up3_1): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (conv2_2): ConvBlock(\n",
       "    (double_conv): Sequential(\n",
       "      (0): Conv2d(384, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (2): ReLU(inplace=True)\n",
       "      (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (5): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (final_conv): Conv2d(32, 3, kernel_size=(1, 1), stride=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate the model architecture first\n",
    "model = UNetPlusPlus(in_channels=1, out_channels=3)\n",
    "\n",
    "# Load the weights\n",
    "model.load_state_dict(torch.load('unetplusplus_epoch_15.pth'))\n",
    "\n",
    "# Put it in eval mode if you're using it for inference\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice Score on Test Set: 0.7693\n"
     ]
    }
   ],
   "source": [
    "def dice_score(preds, targets, epsilon=1e-6):\n",
    "    # Assumes preds are one-hot or softmax outputs (batch, C, H, W)\n",
    "    preds = torch.argmax(preds, dim=1)  # (batch, H, W)\n",
    "    targets = torch.argmax(targets, dim=1)  # (batch, H, W)\n",
    "\n",
    "    dice_total = 0\n",
    "    for cls in range(3):  # For each class\n",
    "        pred_cls = (preds == cls).float()\n",
    "        target_cls = (targets == cls).float()\n",
    "        \n",
    "        intersection = (pred_cls * target_cls).sum()\n",
    "        union = pred_cls.sum() + target_cls.sum()\n",
    "        \n",
    "        dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "        dice_total += dice\n",
    "\n",
    "    return dice_total / 3  # Average over 3 classes\n",
    "\n",
    "total_dice = 0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        outputs = model(images)  # Forward pass\n",
    "        batch_dice = dice_score(outputs, masks)\n",
    "        total_dice += batch_dice.item()\n",
    "        num_batches += 1\n",
    "\n",
    "avg_dice = total_dice / num_batches\n",
    "print(f\"Average Dice Score on Test Set: {avg_dice:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dice Score Interpretation\n",
    "Dice Score\tQuality\tNotes\n",
    "0.90 – 1.0\tExcellent\tNear-perfect segmentation\n",
    "0.80 – 0.90\tGood\tAcceptable for many tasks\n",
    "0.70 – 0.80\tModerate\tNeeds tuning, but decent start\n",
    "< 0.70\tLow\tLikely underfitting or dataset/model issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dice_score_per_class(preds, targets, epsilon=1e-6):\n",
    "    # Convert from softmax/one-hot to label maps\n",
    "    preds = torch.argmax(preds, dim=1)    # (batch, H, W)\n",
    "    targets = torch.argmax(targets, dim=1)  # (batch, H, W)\n",
    "\n",
    "    class_dice_scores = []\n",
    "\n",
    "    for cls in range(3):  # 3 classes\n",
    "        pred_cls = (preds == cls).float()\n",
    "        target_cls = (targets == cls).float()\n",
    "\n",
    "        intersection = (pred_cls * target_cls).sum()\n",
    "        union = pred_cls.sum() + target_cls.sum()\n",
    "\n",
    "        dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "        class_dice_scores.append(dice.item())\n",
    "\n",
    "    return class_dice_scores  # List: [dice_class_0, dice_class_1, dice_class_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice Score for Class 0: 0.9919\n",
      "Average Dice Score for Class 1: 0.6284\n",
      "Average Dice Score for Class 2: 0.6875\n"
     ]
    }
   ],
   "source": [
    "total_dice = [0.0, 0.0, 0.0]\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        outputs = model(images)\n",
    "        dice_scores = dice_score_per_class(outputs, masks)\n",
    "        for i in range(3):\n",
    "            total_dice[i] += dice_scores[i]\n",
    "        num_batches += 1\n",
    "\n",
    "avg_dice_per_class = [d / num_batches for d in total_dice]\n",
    "for i, score in enumerate(avg_dice_per_class):\n",
    "    print(f\"Average Dice Score for Class {i}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Class\tDice Score\tComment\n",
    "0 (Background or dominant class)\t0.9919  The model is almost perfect at segmenting this class. This could be because it's the most represented or easiest to detect (like background or liver in medical imaging).\n",
    "\n",
    "1 (Less represented class)\t0.6284 . This suggests your model struggles more here. Could be due to fewer samples, ambiguous boundaries, or class imbalance.\n",
    "\n",
    "2 (Another minor or difficult class)\t0.6875\t Slightly better than Class 1, but still not ideal. There's room for improvement — maybe the object is smaller, has fuzzy edges, or is similar in intensity to others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Dice Score for Foreground (Classes 1 & 2): 0.6579\n"
     ]
    }
   ],
   "source": [
    "def dice_score_foreground(preds, targets, epsilon=1e-6):\n",
    "    preds = torch.argmax(preds, dim=1)  # (B, H, W)\n",
    "    targets = torch.argmax(targets, dim=1)  # (B, H, W)\n",
    "\n",
    "    dice_scores = []\n",
    "\n",
    "    for cls in [1, 2]:  # Only foreground classes\n",
    "        pred_cls = (preds == cls).float()\n",
    "        target_cls = (targets == cls).float()\n",
    "        \n",
    "        intersection = (pred_cls * target_cls).sum()\n",
    "        union = pred_cls.sum() + target_cls.sum()\n",
    "        \n",
    "        dice = (2. * intersection + epsilon) / (union + epsilon)\n",
    "        dice_scores.append(dice)\n",
    "\n",
    "    return sum(dice_scores) / len(dice_scores)\n",
    "\n",
    "# Compute combined Dice for foreground (classes 1 and 2)\n",
    "total_dice_fg = 0\n",
    "num_batches = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, masks in test_loader:\n",
    "        outputs = model(images)\n",
    "        batch_dice_fg = dice_score_foreground(outputs, masks)\n",
    "        total_dice_fg += batch_dice_fg.item()\n",
    "        num_batches += 1\n",
    "\n",
    "avg_dice_fg = total_dice_fg / num_batches\n",
    "print(f\"Average Dice Score for Foreground (Classes 1 & 2): {avg_dice_fg:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
